{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5902d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import mlflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "\n",
    "from datetime import datetime\n",
    "from hts import HTSRegressor\n",
    "import hts.functions\n",
    "import collections\n",
    "from hts.hierarchy import HierarchyTree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "# settings\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f5ea4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48120, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('./../Prakhar_drafts/data_from_2010_to_2019_unemployment_rate.csv', converters={'ags2': str, 'ags5': str})\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c64e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the pca clusters by Amit \n",
    "df = pd.read_csv('./../Prakhar_drafts/data_from_2010_to_2019_unemployment_rate.csv', converters={'ags2': str, 'ags5': str})\n",
    "df2 = pd.read_csv('./../final_dfs/for_modeling/df_final_stationery.csv', converters={'ags2': str, 'ags5': str}) \n",
    "df = pd.merge(df, df2[['cluster','ags5']], on = 'ags5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1306da75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ags5</th>\n",
       "      <th>date</th>\n",
       "      <th>unemployment_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>13.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01001</td>\n",
       "      <td>2010-02-28</td>\n",
       "      <td>14.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01001</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01001</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01001</td>\n",
       "      <td>2010-05-31</td>\n",
       "      <td>12.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ags5        date  unemployment_rate\n",
       "0  01001  2010-01-31               13.7\n",
       "1  01001  2010-02-28               14.1\n",
       "2  01001  2010-03-31               13.6\n",
       "3  01001  2010-04-30               13.1\n",
       "4  01001  2010-05-31               12.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f15c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ags5</th>\n",
       "      <th>date</th>\n",
       "      <th>unemployment_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48115</th>\n",
       "      <td>16077</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48116</th>\n",
       "      <td>16077</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48117</th>\n",
       "      <td>16077</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48118</th>\n",
       "      <td>16077</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48119</th>\n",
       "      <td>16077</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ags5        date  unemployment_rate\n",
       "48115  16077  2019-08-31                7.0\n",
       "48116  16077  2019-09-30                6.5\n",
       "48117  16077  2019-10-31                6.5\n",
       "48118  16077  2019-11-30                6.3\n",
       "48119  16077  2019-12-31                6.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9167cc97",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f7836a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ags5</th>\n",
       "      <th>date</th>\n",
       "      <th>unemployment_rate</th>\n",
       "      <th>ags2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>13.7</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01001</td>\n",
       "      <td>2010-02-28</td>\n",
       "      <td>14.1</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01001</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>13.6</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01001</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>13.1</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01001</td>\n",
       "      <td>2010-05-31</td>\n",
       "      <td>12.5</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ags5        date  unemployment_rate ags2\n",
       "0  01001  2010-01-31               13.7   01\n",
       "1  01001  2010-02-28               14.1   01\n",
       "2  01001  2010-03-31               13.6   01\n",
       "3  01001  2010-04-30               13.1   01\n",
       "4  01001  2010-05-31               12.5   01"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add AGS 2\n",
    "def get_ags2(x):\n",
    "    return x[0:2]\n",
    "\n",
    "df['ags2'] = df['ags5'].apply(get_ags2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e72b195",
   "metadata": {},
   "source": [
    "## ML Flow Experiment Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ead061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_heirarchical_cluster_model(data, agregate_col, params, cluster_type=\"ags2\"):\n",
    "    \n",
    "    ''' Generate a run name '''\n",
    "    run_name = 'hierarchical_' + '_'.join(str(x) for x in list(params.values())[0:5])\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        \n",
    "        # Create a list of kreis\n",
    "        kreis_list = list(data['ags5'].unique())\n",
    "        \n",
    "        ''' Generate the dataset from the cluster with the ags and total summation '''\n",
    "        print(\"Generating the hierarchical dataset...\")\n",
    "    \n",
    "        # Filter Data by relevant columns \n",
    "        relevant_cols = ['ags5', 'unemployment_rate', 'date']\n",
    "        relevant_cols.append(agregate_col)\n",
    "        df = data[relevant_cols]\n",
    "    \n",
    "        # Get bottom level data - ags5\n",
    "        df_ags5 = df.pivot(index=\"date\", columns=\"ags5\", values=\"unemployment_rate\")\n",
    "        \n",
    "        # Get middle level data - aggregate_col\n",
    "        df_middle = df.groupby([\"date\", agregate_col]).sum().reset_index(drop=False).pivot(index=\"date\", \n",
    "                                                                           columns=agregate_col, \n",
    "                                                                           values=\"unemployment_rate\")\n",
    "        \n",
    "        # Get the top level data\n",
    "        df_total = df.groupby(\"date\")[\"unemployment_rate\"].sum().to_frame().rename(columns={\"unemployment_rate\": \"total\"})\n",
    "        \n",
    "        # Join the data frames\n",
    "        hdf = df_ags5.join(df_middle).join(df_total)\n",
    "\n",
    "        # Set the index in datetime format\n",
    "        hdf.index = pd.to_datetime(hdf.index)\n",
    "        \n",
    "        print(\"The dataset size is\", hdf.shape)\n",
    "        \n",
    "        # Create the hierarchical cluster set \n",
    "        cluster_set = df.groupby(agregate_col)['ags5'].apply(lambda x: list(set(x))).to_dict()\n",
    "        \n",
    "        # Add total to the dictionary\n",
    "        cluster_set['total'] = list(cluster_set.keys())\n",
    "    \n",
    "        ''' Model Fitting '''\n",
    "        \n",
    "        # Get the params\n",
    "        model_type = params['model']\n",
    "        rev_type = params['revision_method']\n",
    "        time_steps = params['time_steps']\n",
    "        g = params['growth']              \n",
    "        sm = params['seasonality_mode'] \n",
    "        sp = params['seasonality_prior_scale'] \n",
    "                    \n",
    "        # Divide the data into train and test sets\n",
    "        train_hdf = hdf.head(len(hdf) - time_steps)\n",
    "        test_hdf = hdf.tail(time_steps)\n",
    "        \n",
    "        print(f\"Fitting the model {model_type} with revision method {rev_type} and growths: {g} and seasonality modes: {sm} and seasonality prior scales: {sp}.\")\n",
    "        \n",
    "        # Fit the model \n",
    "        hts_model = HTSRegressor(model=model_type, revision_method=rev_type, \n",
    "                                 seasonality_mode = sm, seasonality_prior_scale=sp,\n",
    "                                    daily_seasonality=False, yearly_seasonality=True)\n",
    "\n",
    "        hts_model.fit(train_hdf, cluster_set)\n",
    "        \n",
    "        print(f\"Predicting for the next {time_steps} time steps.\")\n",
    "        \n",
    "        # Get the predictions \n",
    "        preds = hts_model.predict(steps_ahead=time_steps)\n",
    "        \n",
    "        ''' Model Evaluation '''\n",
    "        \n",
    "        # Get the predicted vales \n",
    "        actual_preds = preds.tail(time_steps)\n",
    "        \n",
    "        # Check if there are negative values in the predictions \n",
    "        negative_pred = (actual_preds < 0).values.any()\n",
    "        if negative_pred:\n",
    "            print(\"There are negative values in the predictions.\")\n",
    "        else: \n",
    "            print(\"No negative values found in the predictions\")\n",
    "            \n",
    "        # Check if the prediction and test have the same size\n",
    "        assert actual_preds.shape[0] == test_hdf.shape[0]\n",
    "        \n",
    "        # Calculate the mse for each kreis\n",
    "        total_mse = 0\n",
    "        total_rmse = 0\n",
    "        for kreis in kreis_list: \n",
    "            total_mse  += mean_squared_error(y_pred=actual_preds[kreis].values, y_true=test_hdf[kreis].values, squared=True)\n",
    "            total_rmse += mean_squared_error(y_pred=actual_preds[kreis].values, y_true=test_hdf[kreis].values, squared=False)\n",
    "#             print(total_mse, total_rmse)\n",
    "        \n",
    "        # Calculate average mse \n",
    "        average_mse = total_mse/len(kreis_list)\n",
    "        average_rmse = total_rmse/len(kreis_list)\n",
    "        print(\"The average error is:\", average_mse)\n",
    "        \n",
    "        \n",
    "        ''' Log experiment details in ML Flow '''\n",
    "        # Log params\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_param(\"Cluster Type\", cluster_type)\n",
    "        mlflow.log_param(\"Cluster Set\", cluster_set)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"mse\", average_mse)\n",
    "        mlflow.log_metric(\"rmse\", average_rmse)\n",
    "        \n",
    "        negative_pred = 1 if negative_pred else 0 \n",
    "        mlflow.log_metric(\"negative_preds\", negative_pred)        \n",
    "        \n",
    "        return preds\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1778f395",
   "metadata": {},
   "source": [
    "## Model Testing and Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb576cef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set the params \n",
    "params = {\n",
    "    'model':'prophet',\n",
    "    'revision_method':'BU',\n",
    "    'time_steps': 12, \n",
    "    'growth' : \"linear\",\n",
    "    'seasonality_mode' : \"additive\",\n",
    "    'seasonality_prior_scale' : 10,\n",
    "}\n",
    "\n",
    "# Run the function \n",
    "#predictions = train_heirarchical_cluster_model(data=df,\n",
    "#                                 agregate_col='ags2', \n",
    "#                                 params=params,\n",
    "#                                 cluster_type=\"ags2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5202ecbe",
   "metadata": {},
   "source": [
    "Revision types to the model.\n",
    "\n",
    "* **AHP** — average historical proportions (top-down approach),\n",
    "* **PHA** — proportions of historical averages (top-down approach),\n",
    "* **FP** — the forecasted proportions (top-down approach),\n",
    "* **OLS** — the optimal combination using OLS,\n",
    "* **WLSS** - optimal combination using structurally weighted OLS,\n",
    "* **WLSV** - optimal combination using variance-weighted OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1659e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all combinations for models \n",
    "model_types = ['prophet']\n",
    "revisions = ['BU', 'AHP', 'PHA']\n",
    "growths = ['linear', 'logistic']\n",
    "seasonality_modes = ['additive','multiplicative']\n",
    "seasonality_prior_scales = [1,10,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c62b270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: prophet and Revision: BU and growths: linear and seasonality modes: additive and seasonality prior scales: 1\n",
      "Generating the hierarchical dataset...\n",
      "The dataset size is (120, 418)\n",
      "Fitting the model prophet with revision method BU and growths: linear and seasonality modes: additive and seasonality prior scales: 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting models:  10%|█         | 1/10 [1:35:58<14:23:47, 5758.63s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    847\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-9a18dbfe2e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0;31m# Run the prediction model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     predictions = train_heirarchical_cluster_model(data=df,\n\u001b[0m\u001b[1;32m     17\u001b[0m                                                      \u001b[0magregate_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ags2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                                      params=params)\n",
      "\u001b[0;32m<ipython-input-55-511838a9fa82>\u001b[0m in \u001b[0;36mtrain_heirarchical_cluster_model\u001b[0;34m(data, agregate_col, params, cluster_type)\u001b[0m\n\u001b[1;32m     63\u001b[0m                                     daily_seasonality=False, yearly_seasonality=True)\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mhts_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_hdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Predicting for the next {time_steps} time steps.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/DSSGx/lib/python3.8/site-packages/hts/core/regressor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, df, nodes, tree, exogenous, root, distributor, disable_progressbar, show_warnings, **fit_kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         }\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         fitted_models = _do_fit(\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mfunction_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_function_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/DSSGx/lib/python3.8/site-packages/hts/core/utils.py\u001b[0m in \u001b[0;36m_do_fit\u001b[0;34m(nodes, function_kwargs, n_jobs, disable_progressbar, show_warnings, distributor)\u001b[0m\n\u001b[1;32m     37\u001b[0m     )\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     result = distributor.map_reduce(\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0m_do_actual_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     )\n",
      "\u001b[0;32m~/venv/DSSGx/lib/python3.8/site-packages/hts/utilities/distribution.py\u001b[0m in \u001b[0;36mmap_reduce\u001b[0;34m(self, map_function, data, function_kwargs, chunk_size, data_length)\u001b[0m\n\u001b[1;32m    174\u001b[0m         )\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/DSSGx/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    851\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for m in model_types:\n",
    "    for r in revisions:\n",
    "        for g in growths: \n",
    "            for sm in seasonality_modes:\n",
    "                for sp in seasonality_prior_scales: \n",
    "                    print(f\"Model: {m} and Revision: {r} and growths: {g} and seasonality modes: {sm} and seasonality prior scales: {sp}\")\n",
    "\n",
    "                    # Change params \n",
    "                    params['model'] = m\n",
    "                    params['revision_method'] = r\n",
    "                    params['growth'] = g                    \n",
    "                    params['seasonality_mode'] = sm\n",
    "                    params['seasonality_prior_scale'] = sp                    \n",
    "                    \n",
    "                    # Run the prediction model  \n",
    "                    predictions = train_heirarchical_cluster_model(data=df,\n",
    "                                                     agregate_col='ags2', \n",
    "                                                     params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b277d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5422396",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Prophet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-a4c8f998d114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mProphet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Prophet' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0042960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
